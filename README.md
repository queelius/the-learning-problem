# The Learning Problem

Essays on induction, inference, and the search for useful representations.

## Posts

| Post | Topic |
|------|-------|
| `2024-09-10-the-policy/` | When optimization becomes existential threat |
| `2024-09-30-universal-bayes/` | All induction is the same induction |
| `2024-10-15-latent-reasoning-traces/` | Memory as learned prior |
| `2024-12-01-mcts-reasoning/` | Tree search for LLM reasoning |
| `2025-12-19-incomputability-of-simple-learning/` | Why simple learning is impossible |
| `2026-01-18-value-functions-reasoning-traces/` | Value functions over reasoning traces |
| `2026-01-rational-agents-llms/` | From A* to GPT |

## The Theme

**Learning is constrained search, and the constraints shape what gets learned.**

- All induction is Bayesian inference with different knobs
- The simplest learning is incomputable, forcing approximations
- Those approximations—priors, architectures, objectives—shape intelligence

## Documentation

```bash
make docs-serve   # Preview at localhost:8000
```

## Blog

These posts also appear on [metafunctor.com](https://metafunctor.com/series/the-learning-problem/).

## Author

**Alex Towell** — [metafunctor.com](https://metafunctor.com) — [queelius@gmail.com](mailto:queelius@gmail.com)

## License

MIT
